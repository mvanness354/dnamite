{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "import sys \n",
    "sys.path.append(\"../models\")\n",
    "\n",
    "device = torch.device('cuda:4' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_pair_weights(pair_kernel_size, pair_kernel_weight=1):\n",
    "    \n",
    "    # Add neighboring indices to pairs in new dimension\n",
    "    # where neighbors come from square around the pair\n",
    "    # pair kernel size comes from relationship (2x+1)^2 = 2k + 1\n",
    "    # pair_kernel_size = (np.sqrt(2 * pair_kernel_size + 1) - 1) // 2\n",
    "    \n",
    "    # Create coordinate grids\n",
    "    x = torch.arange(2*pair_kernel_size + 1)\n",
    "    y = torch.arange(2*pair_kernel_size + 1)\n",
    "    \n",
    "    # Create meshgrid\n",
    "    X, Y = torch.meshgrid(x, y, indexing=\"ij\")\n",
    "    \n",
    "    # Stack X and Y to form the coordinate tensor\n",
    "    coordinate_tensor = torch.stack((X, Y), dim=2)\n",
    "    \n",
    "    # Get the kernel offset\n",
    "    kernel_offset = coordinate_tensor - pair_kernel_size\n",
    "    \n",
    "    weights = torch.exp(\n",
    "        -torch.square(kernel_offset).sum(dim=2) / (2 * pair_kernel_weight)\n",
    "    )\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "y shape torch.Size([7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 7])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_pair_weights(3).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First on Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mvanness/.venvs/default/lib/python3.10/site-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "data = fetch_openml(data_id=41145) # philippine dataset\n",
    "X, y = data['data'].copy(deep=False), data['target'].copy(deep=False)\n",
    "\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4665, 308)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: Test loss has not improved for 5 consecutive epochs.\n",
      "Number of main features selected:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of interaction features selected:  66\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from dnamite import DNAMiteBinaryClassifier\n",
    "\n",
    "model = DNAMiteBinaryClassifier(\n",
    "    n_features=X_train.shape[1],\n",
    "    n_embed=8,\n",
    "    n_hidden=32,\n",
    "    device=device,\n",
    "    learning_rate=5e-4,\n",
    "    kernel_size=5,\n",
    "    kernel_weight=1,\n",
    "    pair_kernel_size=100,\n",
    "    pair_kernel_weight=10,\n",
    "    entropy_param=1e-3,\n",
    "    gamma=0.5,\n",
    "    reg_param=0.1,\n",
    "    pair_reg_param=0.1,\n",
    ").to(device)\n",
    "\n",
    "# First try to select features\n",
    "model.select_features(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPlIT 0\n",
      "Found selected features. Using only those features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: Test loss has not improved for 5 consecutive epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPlIT 1\n",
      "Found selected features. Using only those features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: Test loss has not improved for 5 consecutive epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPlIT 2\n",
      "Found selected features. Using only those features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: Test loss has not improved for 5 consecutive epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPlIT 3\n",
      "Found selected features. Using only those features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: Test loss has not improved for 5 consecutive epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPlIT 4\n",
      "Found selected features. Using only those features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: Test loss has not improved for 5 consecutive epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    }
   ],
   "source": [
    "# now train the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8385630593309477"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "\n",
    "pred_probs = 1 / (1 + np.exp(-preds))\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, pred_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now test for survival analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/chl8856/DeepHit/master/sample%20data/METABRIC/cleaned_features_final.csv\"\n",
    ")\n",
    "\n",
    "y = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/chl8856/DeepHit/master/sample%20data/METABRIC/label.csv\"\n",
    ")\n",
    "\n",
    "data = pd.concat([X, y], axis=1)\n",
    "X = data.drop([\"event_time\", \"label\"], axis=1)\n",
    "y = np.array(list(zip(data[\"label\"], data[\"event_time\"])), dtype=[('event', 'bool'), ('time', 'float32')])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: Test loss has not improved for 5 consecutive epochs.\n",
      "Number of main features selected:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: Test loss has not improved for 5 consecutive epochs.\n",
      "Number of interaction features selected:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from dnamite import DNAMiteSurvival\n",
    "\n",
    "model = DNAMiteSurvival(\n",
    "    n_features=X_train.shape[1],\n",
    "    n_embed=8,\n",
    "    n_hidden=32,\n",
    "    n_output=100,\n",
    "    device=device,\n",
    "    learning_rate=5e-4,\n",
    "    kernel_size=5,\n",
    "    kernel_weight=1,\n",
    "    pair_kernel_size=10,\n",
    "    pair_kernel_weight=1,\n",
    "    entropy_param=1e-3,\n",
    "    gamma=0.05,\n",
    "    reg_param=0.05,\n",
    "    pair_reg_param=0.1,\n",
    ").to(device)\n",
    "\n",
    "# First try to select features\n",
    "model.select_features(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPlIT 0\n",
      "Found selected features. Using only those features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: Test loss has not improved for 5 consecutive epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPlIT 1\n",
      "Found selected features. Using only those features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: Test loss has not improved for 5 consecutive epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPlIT 2\n",
      "Found selected features. Using only those features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: Test loss has not improved for 5 consecutive epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPlIT 3\n",
      "Found selected features. Using only those features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: Test loss has not improved for 5 consecutive epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPlIT 4\n",
      "Found selected features. Using only those features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: Test loss has not improved for 5 consecutive epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    }
   ],
   "source": [
    "# now train the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                     \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5321649959705601"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "pred_probs = 1 / (1 + np.exp(-preds))\n",
    "surv_preds = 1 - pred_probs\n",
    "\n",
    "test_times = np.linspace(\n",
    "    max(y_train[\"time\"].min(), y_test[y_test[\"event\"] > 0][\"time\"].min()) + 1e-4,\n",
    "    min(y_train[\"time\"].max(), y_test[y_test[\"event\"] > 0][\"time\"].max()) - 1e-4,\n",
    "    100\n",
    ")\n",
    "\n",
    "surv_preds = surv_preds[\n",
    "    :, \n",
    "    np.clip(\n",
    "        np.searchsorted(model.eval_times.cpu().numpy(), test_times),\n",
    "        0, surv_preds.shape[1]-1\n",
    "    )\n",
    "]\n",
    "risk_preds = -1 * np.log(np.clip(surv_preds, 1e-5, 1 - 1e-5))\n",
    "\n",
    "# Get time-dependent AUC\n",
    "from sksurv.metrics import cumulative_dynamic_auc\n",
    "aucs, mean_auc = cumulative_dynamic_auc(y_train, y_test, risk_preds, test_times)\n",
    "mean_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58778626, 0.58778626, 0.58778626, 0.58778626, 0.55866455,\n",
       "       0.55866455, 0.55866455, 0.5700975 , 0.5700975 , 0.5700975 ,\n",
       "       0.50623689, 0.50668132, 0.50668132, 0.5045809 , 0.5045809 ,\n",
       "       0.5058881 , 0.5058881 , 0.5058881 , 0.5058881 , 0.495625  ,\n",
       "       0.44025178, 0.44025178, 0.43888861, 0.43888861, 0.43888861,\n",
       "       0.47208   , 0.47208   , 0.4382915 , 0.4382915 , 0.4376895 ,\n",
       "       0.4376895 , 0.4376895 , 0.50455508, 0.54557696, 0.54557696,\n",
       "       0.49206895, 0.49206895, 0.49206895, 0.48950214, 0.48950214,\n",
       "       0.53516702, 0.53516702, 0.56890388, 0.51693509, 0.51693509,\n",
       "       0.51693509, 0.51693509, 0.4967256 , 0.51236201, 0.51236201,\n",
       "       0.51236201, 0.51047887, 0.51047887, 0.51047887, 0.47800139,\n",
       "       0.47800139, 0.47800139, 0.47800139, 0.47800139, 0.47800139,\n",
       "       0.47800139, 0.47979531, 0.45348853, 0.45348853, 0.45348853,\n",
       "       0.45348853, 0.45348853, 0.45348853, 0.47243549, 0.47243549,\n",
       "       0.49051677, 0.49051677, 0.49051677, 0.49051677, 0.49051677,\n",
       "       0.48960787, 0.48960787, 0.51929346, 0.5324435 , 0.5324435 ,\n",
       "       0.54092465, 0.54096179, 0.54096179, 0.53968669, 0.53968669,\n",
       "       0.53968669, 0.53968669, 0.5275624 , 0.5521323 , 0.5521323 ,\n",
       "       0.5521323 , 0.5521323 , 0.55213395, 0.50882579, 0.4812274 ,\n",
       "       0.48184873, 0.50209874, 0.50209874, 0.50209874, 0.50021262,\n",
       "       0.50021262, 0.51217805, 0.51134503, 0.51134503, 0.51134503,\n",
       "       0.50642802, 0.50642802, 0.50642802, 0.50642802, 0.49336185,\n",
       "       0.49336185, 0.49336185, 0.48167771, 0.48029606, 0.47519233,\n",
       "       0.48430343, 0.48430343, 0.4841277 , 0.4841277 , 0.4841277 ,\n",
       "       0.48466318, 0.50010025, 0.50758316, 0.46945764, 0.46567114,\n",
       "       0.46434458, 0.46434458, 0.46183603, 0.45184514, 0.45241234,\n",
       "       0.45241234, 0.45176835, 0.45442108, 0.45797044, 0.45797044,\n",
       "       0.45797044, 0.45882811, 0.45882811, 0.45882811, 0.45882811,\n",
       "       0.46161628, 0.46161628, 0.46161628, 0.47388591, 0.46355496,\n",
       "       0.45535206, 0.44305956, 0.44305956, 0.43755009, 0.43755009,\n",
       "       0.43755009, 0.43626457, 0.43373294, 0.43373294, 0.4333063 ,\n",
       "       0.44263029, 0.44263029, 0.44478172, 0.44478172, 0.4446057 ,\n",
       "       0.44494804, 0.44449854, 0.44449854, 0.44648723, 0.45608731,\n",
       "       0.45608731, 0.4550191 , 0.4550191 , 0.45653604, 0.45863226,\n",
       "       0.45863226, 0.46408993, 0.46938062, 0.47406299, 0.47465382,\n",
       "       0.46826413, 0.46826413, 0.46826413, 0.45910455, 0.44646917,\n",
       "       0.44507458, 0.4517193 , 0.4517193 , 0.45087168, 0.45087168,\n",
       "       0.45087168, 0.45960653, 0.45960653, 0.4762853 , 0.4686459 ,\n",
       "       0.46786589, 0.46728633, 0.46779409, 0.46779409, 0.46779409,\n",
       "       0.46779409, 0.4608096 , 0.46027023, 0.46027023, 0.4613212 ,\n",
       "       0.45646013, 0.45646013, 0.4574144 , 0.46140191, 0.46140191,\n",
       "       0.46140191, 0.4609482 , 0.46098375, 0.46098375, 0.45899841,\n",
       "       0.46609275, 0.46760685, 0.46962295, 0.46988245, 0.46713218,\n",
       "       0.46842022, 0.46976287, 0.47258097, 0.48008446, 0.48111756,\n",
       "       0.47611041, 0.47527251, 0.47527251, 0.47641469, 0.47641469,\n",
       "       0.47123267, 0.47123267, 0.47349366, 0.47349366, 0.47349366,\n",
       "       0.47628663, 0.47442172, 0.47355513, 0.47461345, 0.4754013 ,\n",
       "       0.47780709, 0.46770562, 0.46770562, 0.4662741 , 0.4662741 ,\n",
       "       0.46532005, 0.46532005, 0.46628116, 0.46588494, 0.46588494,\n",
       "       0.46588494, 0.46675465, 0.47453609, 0.47428402, 0.47428402,\n",
       "       0.48003837, 0.48088593, 0.48088593, 0.47797233, 0.47797233,\n",
       "       0.47797233, 0.47930871, 0.47930871, 0.47930871, 0.47930871,\n",
       "       0.4809142 , 0.4809142 , 0.4809142 , 0.4809142 , 0.49486056,\n",
       "       0.49486056, 0.49486056, 0.49486056, 0.49486056, 0.49550088,\n",
       "       0.49860564, 0.49884851, 0.49315306, 0.49315306, 0.50244654,\n",
       "       0.5034918 , 0.5034918 , 0.50050349, 0.50050349, 0.50050349,\n",
       "       0.49964011, 0.49964011, 0.49035034, 0.49035034, 0.49035034,\n",
       "       0.48760338, 0.48760338, 0.48545688, 0.48545688, 0.48545688,\n",
       "       0.48314952, 0.4772463 , 0.4772463 , 0.47742823, 0.47770096,\n",
       "       0.47770096, 0.48577907, 0.48577907, 0.47581429, 0.48578496,\n",
       "       0.48559493, 0.48092253, 0.48259186, 0.48259186, 0.48030755,\n",
       "       0.47943228, 0.4797193 , 0.4797193 , 0.48369988, 0.48369988,\n",
       "       0.47980545, 0.47867612, 0.47446593, 0.47446593, 0.47446593,\n",
       "       0.47277563, 0.47277563, 0.47277563, 0.47526413, 0.47688483,\n",
       "       0.47688483, 0.47688483, 0.47688483, 0.47688483, 0.47688483,\n",
       "       0.47688483, 0.48491806, 0.48491806, 0.48617657, 0.48919911,\n",
       "       0.48919911, 0.48919911, 0.48919911, 0.48919911, 0.48919911,\n",
       "       0.48919911, 0.48919911, 0.48919911, 0.48919911, 0.49608496,\n",
       "       0.50431639, 0.50601777, 0.50489973, 0.50489973, 0.50489973,\n",
       "       0.50316438, 0.50316438, 0.51870984, 0.51870984, 0.52521119,\n",
       "       0.52575619, 0.52575619, 0.52426511, 0.52426511, 0.51838004,\n",
       "       0.51859993, 0.51398372, 0.51398372, 0.51485988, 0.51485988,\n",
       "       0.51485988, 0.51485988, 0.51927291, 0.51927291, 0.51927291,\n",
       "       0.51927291, 0.52132237, 0.52132237, 0.5271743 , 0.5271743 ,\n",
       "       0.53410622, 0.53410622, 0.53410622, 0.53717621, 0.53717621,\n",
       "       0.53948159, 0.54239642, 0.54239642, 0.54388437, 0.54919975,\n",
       "       0.55465404, 0.55465404, 0.55465404, 0.55465404, 0.55468789,\n",
       "       0.55468789, 0.55468789, 0.55468789, 0.54664863, 0.54734271,\n",
       "       0.54529632, 0.5475031 , 0.54919988, 0.54919988, 0.55456986,\n",
       "       0.55456986, 0.55835868, 0.55785218, 0.55867845, 0.55867845,\n",
       "       0.55867845, 0.55867845, 0.55867845, 0.55867845, 0.55867845,\n",
       "       0.55972122, 0.56166996, 0.56311262, 0.56311262, 0.56311262,\n",
       "       0.56303471, 0.56303471, 0.5615014 , 0.56387242, 0.56387242,\n",
       "       0.56277963, 0.56039748, 0.55936177, 0.55936177, 0.55390603,\n",
       "       0.55390603, 0.55831678, 0.55831678, 0.56033178, 0.55968975,\n",
       "       0.55968975, 0.55968975, 0.55593091, 0.55593091, 0.55593091,\n",
       "       0.55593091, 0.55442886, 0.55442886, 0.56550985, 0.56550985,\n",
       "       0.56550985, 0.56759571, 0.56759571, 0.56834456, 0.57028877,\n",
       "       0.57028877, 0.57028877, 0.56651035, 0.56773073, 0.56849988,\n",
       "       0.56849988, 0.56849988, 0.56849988, 0.57066231, 0.57066231,\n",
       "       0.57066231, 0.57066231, 0.56426703, 0.56360464, 0.56388201,\n",
       "       0.56099426, 0.56099426, 0.56334126, 0.56334126, 0.56334126,\n",
       "       0.56334126, 0.56334126, 0.56334126, 0.56013358, 0.56238749,\n",
       "       0.56238749, 0.56238749, 0.56235961, 0.56235961, 0.56274376,\n",
       "       0.55999757, 0.55999757, 0.56609348, 0.56754247, 0.56754247,\n",
       "       0.56754247, 0.5641639 , 0.5641639 , 0.5641639 , 0.56438167,\n",
       "       0.56438167, 0.56438167, 0.56412206, 0.56412206, 0.56412206,\n",
       "       0.55993994, 0.55993994, 0.56411612, 0.56411612, 0.56411612,\n",
       "       0.56430253, 0.56894839, 0.56894839, 0.56894839, 0.57049208,\n",
       "       0.56225945, 0.56225945, 0.56225945, 0.5614593 , 0.55242719,\n",
       "       0.55242719, 0.55242719, 0.55242719, 0.5565766 , 0.55894446,\n",
       "       0.55894446, 0.55702851, 0.55702851, 0.55702851, 0.55702851,\n",
       "       0.56131553, 0.56131553, 0.57106394, 0.57475695, 0.57032227,\n",
       "       0.56299961, 0.56135881, 0.54967212, 0.54967212, 0.54967212,\n",
       "       0.54976419, 0.54976419, 0.55338072, 0.55338072, 0.55338072,\n",
       "       0.54440882, 0.54323261, 0.53859762, 0.53727085, 0.5472705 ,\n",
       "       0.5447553 , 0.5518239 , 0.54854797, 0.54415496, 0.54415496,\n",
       "       0.5475775 , 0.55146237, 0.54281457, 0.54281457, 0.53685239,\n",
       "       0.53685239, 0.53685239, 0.53685239, 0.53685239, 0.53685239,\n",
       "       0.54342398, 0.54204698, 0.54204698, 0.54443838, 0.54079166,\n",
       "       0.54079166, 0.54079166, 0.54079166, 0.54079166, 0.53861889,\n",
       "       0.53861889, 0.53420996, 0.54011862, 0.54011862, 0.54011862,\n",
       "       0.5332043 , 0.53437275, 0.53437275, 0.53437275, 0.53437275,\n",
       "       0.53437275, 0.5358893 , 0.53310046, 0.53310046, 0.53310046,\n",
       "       0.53310046, 0.5238858 , 0.5238858 , 0.5238858 , 0.5238858 ,\n",
       "       0.52862147, 0.52584562, 0.52584562, 0.52584562, 0.53914036,\n",
       "       0.53279831, 0.53432914, 0.53115054, 0.53118853, 0.53070773,\n",
       "       0.52611711, 0.52611711, 0.52611711, 0.52611711, 0.52611711,\n",
       "       0.52611711, 0.52386919, 0.52386919, 0.52386919, 0.54112851,\n",
       "       0.54112851, 0.54112851, 0.53901299, 0.53901299, 0.53289761,\n",
       "       0.53289761, 0.52513684, 0.52460503, 0.52460503, 0.52460503,\n",
       "       0.52460503, 0.52460503, 0.52460503, 0.52460503, 0.52809465,\n",
       "       0.52809465, 0.52809465, 0.52809465, 0.52809465, 0.52809465,\n",
       "       0.52833029, 0.52833029, 0.52833029, 0.52833029, 0.52833029,\n",
       "       0.52833029, 0.52519359, 0.53157061, 0.52821436, 0.53457986,\n",
       "       0.53457986, 0.53457986, 0.53457986, 0.53457986, 0.53457986,\n",
       "       0.53457986, 0.52732486, 0.52586469, 0.52586469, 0.52586469,\n",
       "       0.53366262, 0.53366262, 0.53366262, 0.53366262, 0.53366262,\n",
       "       0.53366262, 0.53366262, 0.53366262, 0.53366262, 0.53366262,\n",
       "       0.55400423, 0.55400423, 0.55400423, 0.55400423, 0.55400423,\n",
       "       0.55384918, 0.55384918, 0.53386523, 0.5283916 , 0.5283916 ,\n",
       "       0.53110578, 0.53110578, 0.53110578, 0.53110578, 0.52035649,\n",
       "       0.52035649, 0.51233329, 0.50931391, 0.50931391, 0.50931391,\n",
       "       0.51395723, 0.51395723, 0.51395723, 0.51395723, 0.51684599,\n",
       "       0.51684599, 0.51637007, 0.51946885, 0.51946885, 0.51203572,\n",
       "       0.51203572, 0.50129821, 0.50129821, 0.50129821, 0.49135036,\n",
       "       0.49135036, 0.49135036, 0.49135036, 0.49135036, 0.49135036,\n",
       "       0.49135036, 0.49135036, 0.49135036, 0.49710103, 0.49710103,\n",
       "       0.49710103, 0.50250967, 0.50250967, 0.50250967, 0.50250967,\n",
       "       0.50250967, 0.50250967, 0.51091688, 0.51874191, 0.51874191,\n",
       "       0.53386942, 0.56217376, 0.56217376, 0.56217376, 0.56217376,\n",
       "       0.56217376, 0.56217376, 0.56217376, 0.56217376, 0.56217376,\n",
       "       0.56719699, 0.5783033 , 0.59680052, 0.59680052, 0.56016203,\n",
       "       0.56016203, 0.56016203, 0.57896655, 0.57896655, 0.57896655,\n",
       "       0.57896655, 0.57896655, 0.57896655, 0.57896655, 0.57896655,\n",
       "       0.57896655, 0.57896655, 0.57715749, 0.57715749, 0.57715749,\n",
       "       0.57715749, 0.57715749, 0.56630494, 0.58782817, 0.58782817,\n",
       "       0.58782817, 0.58782817, 0.56439126, 0.56439126, 0.56439126,\n",
       "       0.56439126, 0.56439126, 0.56439126, 0.56439126, 0.56439126,\n",
       "       0.5838535 , 0.57225857, 0.58999244, 0.58999244, 0.58999244,\n",
       "       0.58999244, 0.58999244, 0.58999244, 0.58999244, 0.58999244,\n",
       "       0.58999244, 0.58999244, 0.58999244, 0.58999244, 0.58999244,\n",
       "       0.58999244, 0.58999244, 0.58999244, 0.58999244, 0.58999244,\n",
       "       0.58999244, 0.58999244, 0.58999244, 0.58999244, 0.5437187 ,\n",
       "       0.5437187 , 0.5437187 , 0.5437187 , 0.5437187 , 0.5437187 ,\n",
       "       0.5437187 , 0.5437187 , 0.5437187 , 0.5437187 , 0.5437187 ,\n",
       "       0.5437187 , 0.5437187 , 0.5437187 , 0.5437187 , 0.5437187 ,\n",
       "       0.5437187 , 0.5437187 , 0.52536854, 0.52536854, 0.52536854,\n",
       "       0.51021282, 0.51021282, 0.51021282, 0.51021282, 0.51021282,\n",
       "       0.51021282, 0.51021282, 0.52884142, 0.52884142, 0.52884142,\n",
       "       0.52884142, 0.52884142, 0.52884142, 0.52884142, 0.52884142,\n",
       "       0.52884142, 0.5169376 , 0.5169376 , 0.47142777, 0.47142777,\n",
       "       0.47142777, 0.47142777, 0.47142777, 0.47142777, 0.47142777,\n",
       "       0.47142777, 0.47142777, 0.47142777, 0.47142777, 0.47142777,\n",
       "       0.47142777, 0.47142777, 0.47142777, 0.47142777, 0.47142777,\n",
       "       0.47142777, 0.45841654, 0.45841654, 0.45841654, 0.45841654,\n",
       "       0.45841654, 0.50009077, 0.54637894, 0.51049586, 0.51049586,\n",
       "       0.51049586, 0.51049586, 0.51049586, 0.51049586, 0.51049586,\n",
       "       0.51049586, 0.51049586, 0.51049586, 0.51049586, 0.51049586,\n",
       "       0.51049586, 0.51049586, 0.51049586, 0.51049586, 0.4766472 ,\n",
       "       0.4766472 , 0.4766472 , 0.4766472 , 0.4766472 , 0.4766472 ,\n",
       "       0.4766472 , 0.4766472 , 0.48091413, 0.48091413, 0.48091413,\n",
       "       0.48091413, 0.48091413, 0.48091413, 0.48091413, 0.48091413,\n",
       "       0.48091413, 0.48091413, 0.48091413, 0.48091413, 0.48091413,\n",
       "       0.48091413, 0.48091413, 0.48091413, 0.48091413, 0.48091413,\n",
       "       0.48091413, 0.48091413, 0.48091413, 0.48091413, 0.48091413,\n",
       "       0.48091413, 0.48091413, 0.48091413, 0.48091413, 0.48091413,\n",
       "       0.48091413, 0.48091413, 0.48091413, 0.48091413, 0.48091413,\n",
       "       0.48091413, 0.48091413, 0.48091413, 0.48091413, 0.48091413,\n",
       "       0.48091413, 0.48091413, 0.48091413, 0.48091413, 0.48091413,\n",
       "       0.48091413, 0.48091413, 0.48091413, 0.48091413, 0.48091413,\n",
       "       0.48091413, 0.48091413, 0.48091413, 0.48091413, 0.48091413,\n",
       "       0.48091413, 0.48091413, 0.48091413, 0.48091413, 0.48091413,\n",
       "       0.48091413, 0.48091413, 0.48091413, 0.48091413, 0.48091413,\n",
       "       0.48091413, 0.48091413, 0.48091413, 0.48091413, 0.48091413,\n",
       "       0.48091413, 0.48091413, 0.48091413, 0.48091413, 0.48091413,\n",
       "       0.48091413, 0.48091413, 0.48091413, 0.48091413, 0.48091413,\n",
       "       0.48091413, 0.48091413, 0.48091413, 0.48091413, 0.48091413,\n",
       "       0.40601372, 0.40601372, 0.40601372, 0.40601372, 0.40601372,\n",
       "       0.40601372, 0.40601372, 0.40601372, 0.40601372, 0.40601372,\n",
       "       0.40601372, 0.40601372, 0.40601372, 0.40601372, 0.40601372,\n",
       "       0.40601372, 0.40601372, 0.40601372, 0.40601372, 0.40601372,\n",
       "       0.40601372, 0.40601372, 0.40601372, 0.40601372, 0.40601372,\n",
       "       0.40601372, 0.40601372, 0.40601372, 0.40601372, 0.40601372,\n",
       "       0.40601372, 0.40601372, 0.40601372, 0.34886006, 0.34886006,\n",
       "       0.34886006, 0.34886006, 0.34886006, 0.34886006, 0.34886006,\n",
       "       0.34886006, 0.34886006, 0.34886006, 0.31598554, 0.31598554,\n",
       "       0.31598554, 0.31598554, 0.31598554, 0.31598554, 0.31598554,\n",
       "       0.31598554, 0.31598554, 0.31598554, 0.31598554, 0.31598554,\n",
       "       0.31598554, 0.31598554, 0.31598554, 0.31598554, 0.31598554])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
