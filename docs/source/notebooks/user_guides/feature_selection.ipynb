{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "This user guide details how DNAMite can be used for feature selection / feature-sparse prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Bother with Feature Selection?\n",
    "\n",
    "When training a black-box machine learning model, it is common practice to use all available features even for high-dimensional datasets, as modern ML models can easily handle many features. When training a glass-box model, however, we need to care about both predictive performance as well as accurate and utility of explanations. While glass-box models often have good accurate on high-dimensional datasets, model explanations are much more likely to be impaired in such settings. In particular, when sets of correlated features are all used in the same dataset, additive models like DNAMite run into identifiability issues with how to spread contribution across the feature set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNAMite Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "sns.set_theme()\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "df_train = pd.read_csv(\"mortality_tab_train.csv\")\n",
    "X_train = df_train.drop([\"target\"], axis=1)\n",
    "y_train = df_train[\"target\"]\n",
    "\n",
    "df_test = pd.read_csv(\"mortality_tab_test.csv\")\n",
    "X_test = df_test.drop([\"target\"], axis=1)\n",
    "y_test = df_test[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretizing features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 714/714 [00:00<00:00, 1236.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPlIT 0\n",
      "TRAINING MAINS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at 8 epochs: Test loss has not improved for 5 consecutive epochs.\n",
      "SPlIT 1\n",
      "TRAINING MAINS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at 7 epochs: Test loss has not improved for 5 consecutive epochs.\n",
      "SPlIT 2\n",
      "TRAINING MAINS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at 7 epochs: Test loss has not improved for 5 consecutive epochs.\n",
      "SPlIT 3\n",
      "TRAINING MAINS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at 7 epochs: Test loss has not improved for 5 consecutive epochs.\n",
      "SPlIT 4\n",
      "TRAINING MAINS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at 7 epochs: Test loss has not improved for 5 consecutive epochs.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdnamite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DNAMiteBinaryClassifier\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m DNAMiteBinaryClassifier(n_features\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], device\u001b[38;5;241m=\u001b[39mdevice, fit_pairs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dnamite/public_repo/dnamite/dnamite/models/dnamite.py:2429\u001b[0m, in \u001b[0;36mDNAMiteBinaryClassifier.fit\u001b[0;34m(self, X, y, partialed_feats)\u001b[0m\n\u001b[1;32m   2412\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, partialed_feats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2413\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2414\u001b[0m \u001b[38;5;124;03m    Train model.\u001b[39;00m\n\u001b[1;32m   2415\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2427\u001b[0m \u001b[38;5;124;03m        A list of features that should be fit completely before fitting all other features.\u001b[39;00m\n\u001b[1;32m   2428\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2429\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartialed_feats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartialed_feats\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dnamite/public_repo/dnamite/dnamite/models/dnamite.py:1430\u001b[0m, in \u001b[0;36mBaseDNAMiteModel.fit\u001b[0;34m(self, X, y, partialed_feats)\u001b[0m\n\u001b[1;32m   1414\u001b[0m     \u001b[38;5;66;03m# model.feature_bins = self.feature_bins\u001b[39;00m\n\u001b[1;32m   1415\u001b[0m     \n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;66;03m# # Compute the bin counts\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1425\u001b[0m     \u001b[38;5;66;03m#         for col1, col2 in pairs_list\u001b[39;00m\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;66;03m#     ]\u001b[39;00m\n\u001b[1;32m   1428\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mappend(model)\n\u001b[0;32m-> 1430\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_bin_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1432\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/dnamite/public_repo/dnamite/dnamite/models/dnamite.py:1055\u001b[0m, in \u001b[0;36mBaseDNAMiteModel._compute_bin_scores\u001b[0;34m(self, ignore_missing_bin_in_intercept)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_bin_scores\u001b[39m(\u001b[38;5;28mself\u001b[39m, ignore_missing_bin_in_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m-> 1055\u001b[0m     has_missing_bins \u001b[38;5;241m=\u001b[39m [bins[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m bins[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m bins \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_bins]\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels:\n\u001b[1;32m   1059\u001b[0m         model\u001b[38;5;241m.\u001b[39mcompute_intercept(\n\u001b[1;32m   1060\u001b[0m             model\u001b[38;5;241m.\u001b[39mbin_counts, \n\u001b[1;32m   1061\u001b[0m             ignore_missing_bin\u001b[38;5;241m=\u001b[39mignore_missing_bin_in_intercept,\n\u001b[1;32m   1062\u001b[0m             has_missing_bin\u001b[38;5;241m=\u001b[39mhas_missing_bins\n\u001b[1;32m   1063\u001b[0m         )\n",
      "File \u001b[0;32m~/dnamite/public_repo/dnamite/dnamite/models/dnamite.py:1055\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_bin_scores\u001b[39m(\u001b[38;5;28mself\u001b[39m, ignore_missing_bin_in_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m-> 1055\u001b[0m     has_missing_bins \u001b[38;5;241m=\u001b[39m [\u001b[43mbins\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m!=\u001b[39m bins[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m bins \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_bins]\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels:\n\u001b[1;32m   1059\u001b[0m         model\u001b[38;5;241m.\u001b[39mcompute_intercept(\n\u001b[1;32m   1060\u001b[0m             model\u001b[38;5;241m.\u001b[39mbin_counts, \n\u001b[1;32m   1061\u001b[0m             ignore_missing_bin\u001b[38;5;241m=\u001b[39mignore_missing_bin_in_intercept,\n\u001b[1;32m   1062\u001b[0m             has_missing_bin\u001b[38;5;241m=\u001b[39mhas_missing_bins\n\u001b[1;32m   1063\u001b[0m         )\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "from dnamite.models import DNAMiteBinaryClassifier\n",
    "\n",
    "model = DNAMiteBinaryClassifier(n_features=X_train.shape[1], device=device, fit_pairs=False)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "DNAMite has multiple hyperparameters that can be set to control the "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
